# Test Fixtures Documentation

This directory contains all test fixtures for the LMB filter implementation. All fixtures are stored flat with prefix-based naming for easy discovery.

## Naming Convention

| Prefix | Meaning | Example |
|--------|---------|---------|
| `step_*` | Step-by-step validation fixtures | `step_ss_lmb_seed42.json` |
| `trial_*` | End-to-end trial fixtures | `trial_ms_seed42.json` |
| `bench_*` | Benchmark fixtures | `bench_n5_s1_lmb_lbp.json` |
| `scenario_*` | Scenario input data | `scenario_n5_s1.json` |
| `*_ss_*` | Single-sensor | `step_ss_lmb_seed42.json` |
| `*_ms_*` | Multi-sensor | `step_ms_aa_lmb_seed42.json` |

## Fixture Types

### 1. Step-by-Step Fixtures (`step_*.json`)

**Purpose**: Detailed validation of intermediate filter states at each timestep.

**Generated By**:
- MATLAB scripts in `vendor/multisensor-lmb-filters/` repository (external)
- Scripts: `generate_lmb_step_by_step.m`, `generate_multisensor_step_by_step.m`, etc.
- Generated with seed 42 for deterministic results

**Schema**: Contains filter configuration, model parameters, and expected outputs for each step:
```json
{
  "seed": 42,
  "timestep": 100,
  "filterType": "LMB",
  "numberOfSensors": 1,
  "model": { ... },
  "steps": [
    {
      "prediction": { ... },
      "association": { ... },
      "update": { ... },
      "cardinality": { ... },
      "tracks": [ ... ]
    }
  ]
}
```

**Used By**:
- `tests/ss_lmb.rs` - Single-sensor LMB equivalence tests
- `tests/ss_lmbm.rs` - Single-sensor LMBM equivalence tests
- `tests/ms_lmb.rs` - Multi-sensor IC-LMB equivalence tests
- `tests/ms_lmbm.rs` - Multi-sensor LMBM equivalence tests
- `tests/ms_variants.rs` - Multi-sensor variant (AA, GA, PU, IC) equivalence tests
- `python/tests/test_equivalence.py` - Python binding validation

**Files**:
- `step_ss_lmb_seed42.json` - Single-sensor LMB (100 timesteps)
- `step_ss_lmbm_seed42.json` - Single-sensor LMBM (100 timesteps)
- `step_ms_lmb_seed42.json` - Multi-sensor IC-LMB (100 timesteps, 2 sensors)
- `step_ms_lmbm_seed42.json` - Multi-sensor LMBM (100 timesteps, 2 sensors)
- `step_ms_aa_lmb_seed42.json` - Arithmetic Average LMB (100 timesteps, 2 sensors)
- `step_ms_ga_lmb_seed42.json` - Geometric Average LMB (100 timesteps, 2 sensors)
- `step_ms_ic_lmb_seed42.json` - Iterated Corrector LMB (same as step_ms_lmb)
- `step_ms_pu_lmb_seed42.json` - Parallel Update LMB (100 timesteps, 2 sensors)

---

### 2. Trial Fixtures (`trial_*.json`)

**Purpose**: End-to-end filter execution with complete measurement sequences.

**Generated By**:
- MATLAB scripts in `vendor/multisensor-lmb-filters/` repository (external)
- Scripts: `generate_trial_fixture.m`, `generate_multisensor_trial.m`
- Various configurations for different test scenarios

**Schema**: Complete filter configuration with measurement sequences:
```json
{
  "seed": 42,
  "num_steps": 100,
  "model": { ... },
  "measurements": [ ... ],
  "expected_tracks": [ ... ]
}
```

**Used By**:
- `tests/ss_lmb.rs` - Integration tests for complete filter runs
- `tests/ms_lmb.rs` - Multi-sensor integration tests
- `python/tests/test_equivalence.py` - End-to-end Python binding tests

**Files**:
- `trial_ss_seed42.json` - Full single-sensor trial (100 steps)
- `trial_ss_quick_seed42.json` - Quick single-sensor trial (10 steps)
- `trial_ss_detection_quick_seed42.json` - Detection-focused quick trial
- `trial_ms_seed42.json` - Full multi-sensor trial (100 steps, 2 sensors)
- `trial_ms_clutter_quick_seed42.json` - Clutter-heavy quick trial
- `trial_ms_detection_quick_seed42.json` - Multi-sensor detection quick trial

---

### 3. Benchmark Fixtures (`bench_*.json`)

**Purpose**: Performance benchmarking with expected outputs for validation.

**Generated By**:
- MATLAB scripts in `benchmarks/matlab/` (when they exist) or `vendor/multisensor-lmb-filters/`
- Scripts: `generate_benchmark_fixtures.m`
- Generated for various configurations (n=objects, s=sensors)

**Schema**: Benchmark configuration with scenario reference and expected results:
```json
{
  "scenario_file": "scenario_n5_s1.json",
  "num_sensors": 1,
  "num_steps": 100,
  "seed": 42,
  "filter": {
    "type": "LMB",
    "associator": { "type": "LBP", "params": { ... } }
  },
  "model": { ... },
  "thresholds": { ... },
  "steps": [
    {
      "step": 0,
      "num_tracks": 5,
      "tracks": [ { "label": 1, "mean": [x, y, vx, vy] }, ... ]
    }
  ]
}
```

**Used By**:
- `tests/bench_fixtures.rs` - Automated fixture-driven benchmark validation
- `benchmarks/run_benchmarks.sh` - Performance comparison scripts
- `benchmarks/run_benchmarks/run_rust.rs` - Rust benchmark runner
- `python/tests/test_benchmark_fixtures.py` - Python benchmark validation

**Files** (nX_sY = X objects, Y sensors):
- `bench_n5_s1_lmb_lbp.json` - 5 objects, 1 sensor, LMB-LBP
- `bench_n5_s2_aa_lmb_lbp.json` - 5 objects, 2 sensors, AA-LMB-LBP
- `bench_n5_s2_ga_lmb_lbp.json` - 5 objects, 2 sensors, GA-LMB-LBP
- `bench_n5_s2_ic_lmb_lbp.json` - 5 objects, 2 sensors, IC-LMB-LBP
- `bench_n5_s2_pu_lmb_lbp.json` - 5 objects, 2 sensors, PU-LMB-LBP
- `bench_n10_s1_lmb_lbp.json` - 10 objects, 1 sensor, LMB-LBP
- `bench_n10_s2_aa_lmb_lbp.json` - 10 objects, 2 sensors, AA-LMB-LBP
- `bench_n10_s2_ga_lmb_lbp.json` - 10 objects, 2 sensors, GA-LMB-LBP
- `bench_n10_s2_ic_lmb_lbp.json` - 10 objects, 2 sensors, IC-LMB-LBP
- `bench_n10_s2_pu_lmb_lbp.json` - 10 objects, 2 sensors, PU-LMB-LBP
- `bench_n10_s4_aa_lmb_lbp.json` - 10 objects, 4 sensors, AA-LMB-LBP
- `bench_n10_s4_ga_lmb_lbp.json` - 10 objects, 4 sensors, GA-LMB-LBP
- `bench_n10_s4_ic_lmb_lbp.json` - 10 objects, 4 sensors, IC-LMB-LBP
- `bench_n10_s4_pu_lmb_lbp.json` - 10 objects, 4 sensors, PU-LMB-LBP

---

### 4. Scenario Files (`scenario_*.json`)

**Purpose**: Input data (measurements, ground truth) for benchmark scenarios.

**Generated By**:
- MATLAB scripts in `vendor/multisensor-lmb-filters/` or `benchmarks/matlab/`
- Scripts: `generate_bouncing_scenario.m` or similar
- Generates ground truth trajectories and sensor measurements
- Seed-based deterministic generation

**Schema**: Simulation parameters and measurement sequences:
```json
{
  "num_sensors": 2,
  "num_steps": 100,
  "seed": 42,
  "steps": [
    {
      "ground_truth": [ ... ],
      "sensor_readings": [
        [ [x1, y1], [x2, y2], ... ],  // Sensor 1 measurements
        [ [x1, y1], [x2, y2], ... ]   // Sensor 2 measurements
      ]
    }
  ]
}
```

**Used By**:
- `tests/bench_fixtures.rs` - Loads scenarios via `scenario_file` reference in bench fixtures
- `benchmarks/run_benchmarks/run_rust.rs` - Benchmark execution
- `benchmarks/run_benchmarks/run_octave.m` - MATLAB/Octave benchmark execution
- `benchmarks/run_benchmarks/run_python.py` - Python benchmark execution

**Relationship**: Each `bench_*.json` fixture references a scenario file via the `scenario_file` field.

**Files** (nX_sY = X objects, Y sensors):
- `scenario_n5_s1.json` - 5 objects, 1 sensor (referenced by bench_n5_s1_lmb_lbp.json)
- `scenario_n5_s2.json` - 5 objects, 2 sensors (referenced by bench_n5_s2_*.json)
- `scenario_n10_s1.json` - 10 objects, 1 sensor (referenced by bench_n10_s1_lmb_lbp.json)
- `scenario_n10_s2.json` - 10 objects, 2 sensors (referenced by bench_n10_s2_*.json)
- `scenario_n10_s4.json` - 10 objects, 4 sensors (referenced by bench_n10_s4_*.json)
- `scenario_n20_s1.json` - 20 objects, 1 sensor
- `scenario_n20_s2.json` - 20 objects, 2 sensors
- `scenario_n20_s4.json` - 20 objects, 4 sensors
- `scenario_n20_s8.json` - 20 objects, 8 sensors
- `scenario_n50_s8.json` - 50 objects, 8 sensors

---

## Fixture Integrity

All fixtures are validated for integrity using SHA256 hashes in `python/tests/test_fixture_determinism.py`. This ensures:
1. Fixtures haven't been accidentally modified
2. Fixtures are deterministic and reproducible
3. No unexpected files exist in the fixtures directory

## Loading Fixtures

### Rust
```rust
// Helper functions in tests/helpers/fixtures.rs
let path = load_lmb_fixture_path();  // Returns "tests/fixtures/step_ss_lmb_seed42.json"
let fixture: LmbFixture = load_fixture_from_path(path);

// Direct loading
let fixture: Fixture = serde_json::from_str(&fs::read_to_string("tests/fixtures/bench_n5_s1_lmb_lbp.json")?)?;
```

### Python
```python
# Helper functions in python/tests/conftest.py
from conftest import load_fixture

fixture = load_fixture("step_ss_lmb_seed42.json")
```

## Generating New Fixtures

To generate new fixtures:

1. **Navigate to MATLAB repository**: `cd vendor/multisensor-lmb-filters/`
2. **Run generation script**: e.g., `generate_lmb_step_by_step(42, 100)` in MATLAB/Octave
3. **Copy to this directory**: `cp output.json vendor/multisensor-lmb-filters-rs/tests/fixtures/`
4. **Follow naming convention**: Use appropriate prefix (`step_`, `trial_`, `bench_`, `scenario_`)
5. **Update hash file**: Run `pytest python/tests/test_fixture_determinism.py` to see new hash
6. **Add hash to test**: Update `EXPECTED_HASHES` in `test_fixture_determinism.py`

## Fixture Statistics

**Total fixtures**: 38
- Step-by-step: 8 files (~15-50 MB each)
- Trials: 6 files (~2-10 MB each)
- Benchmarks: 14 files (~5-20 MB each)
- Scenarios: 10 files (~1-5 MB each)

**Total size**: ~300-500 MB

## Related Documentation

- Benchmark results: `../../README_BENCHMARKS.md`
- Test helpers: `../helpers/README.md` (if exists)
- MATLAB generation scripts: `vendor/multisensor-lmb-filters/` (external repository)
